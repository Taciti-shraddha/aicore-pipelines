apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: my-inference-scenario
  annotations:
    scenarios.ai.sap.com/name: "my-inference-scenario"
    scenarios.ai.sap.com/description: "Inference scenario for my trained model."
    executables.ai.sap.com/name: "my-inference-serving"
    executables.ai.sap.com/description: "Serving executable for inference."
  labels:
    ai.sap.com/version: "1.0.0"
spec:
  template:
    apiVersion: serving.kserve.io/v1beta1
    metadata:
      labels: |
        ai.sap.com/resourcePlan: starter
   spec: |
  predictor:
    minReplicas: 1
    containers:
    - name: kserve-container
      image: docker.io/myrepo/my-inference-image:latest
      ports:
        - containerPort: 9001
          protocol: TCP
      args: ["--model", "/models/my_model_file"]

